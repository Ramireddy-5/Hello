{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOY3hb9RCAjRJnjPeGlujr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramireddy-5/Hello/blob/main/exp3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIdIqzvtALyX",
        "outputId": "0a3ec72a-ea68-4afa-95d0-e8df1f714179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: Larry Page and Sergey Brin, two students at Stanford University, USA, started\n",
            "Backrub in early 1996.\n",
            "➡️ Extracted Entities:\n",
            "   Larry  [PERSON]\n",
            "   Page  [ORGANIZATION]\n",
            "   Sergey Brin  [PERSON]\n",
            "   Stanford University  [ORGANIZATION]\n",
            "   USA  [ORGANIZATION]\n",
            "   Backrub  [PERSON]\n",
            "\n",
            "Sentence: They made it into a company, Google Inc., on September\n",
            "7, 1998 at a friend's garage in Menlo Park, California.\n",
            "➡️ Extracted Entities:\n",
            "   Google Inc.  [PERSON]\n",
            "   Menlo Park  [GPE]\n",
            "   California  [GPE]\n",
            "\n",
            "Sentence: In February 1999, the\n",
            "company moved to 165 University Ave., Palo Alto, California, and then moved\n",
            "to another place called the Googleplex.\n",
            "➡️ Extracted Entities:\n",
            "   University  [ORGANIZATION]\n",
            "   Palo Alto  [PERSON]\n",
            "   California  [GPE]\n",
            "   Googleplex  [ORGANIZATION]\n",
            "\n",
            "Sentence: In September 2001, Google's rating\n",
            "system (PageRank, for saying which information is more helpful) got a U.S.\n",
            "Patent.\n",
            "➡️ Extracted Entities:\n",
            "   Google  [PERSON]\n",
            "   PageRank  [ORGANIZATION]\n",
            "   U.S.  [GPE]\n",
            "\n",
            "Sentence: The patent was to Stanford University, with Lawrence (Larry) Page as\n",
            "the inventor.\n",
            "➡️ Extracted Entities:\n",
            "   Stanford University  [ORGANIZATION]\n",
            "   Lawrence  [GPE]\n",
            "   Larry  [PERSON]\n",
            "\n",
            "Sentence: Google makes a percentage of its money through America Online\n",
            "and InterActiveCorp.\n",
            "➡️ Extracted Entities:\n",
            "   Google  [GPE]\n",
            "   America Online  [ORGANIZATION]\n",
            "   InterActiveCorp  [ORGANIZATION]\n",
            "\n",
            "Sentence: It has a special group known as the Partner Solutions\n",
            "Organization (PSO).\n",
            "➡️ Extracted Entities:\n",
            "   Partner Solutions Organization  [ORGANIZATION]\n",
            "   PSO  [ORGANIZATION]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk, sent_tokenize\n",
        "\n",
        "# Download required resources (only once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Sample Input Paragraph\n",
        "paragraph = \"\"\"Larry Page and Sergey Brin, two students at Stanford University, USA, started\n",
        "Backrub in early 1996. They made it into a company, Google Inc., on September\n",
        "7, 1998 at a friend's garage in Menlo Park, California. In February 1999, the\n",
        "company moved to 165 University Ave., Palo Alto, California, and then moved\n",
        "to another place called the Googleplex. In September 2001, Google's rating\n",
        "system (PageRank, for saying which information is more helpful) got a U.S.\n",
        "Patent. The patent was to Stanford University, with Lawrence (Larry) Page as\n",
        "the inventor. Google makes a percentage of its money through America Online\n",
        "and InterActiveCorp. It has a special group known as the Partner Solutions\n",
        "Organization (PSO).\"\"\"\n",
        "\n",
        "# Step 1: Sentence tokenization\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "for sent in sentences:\n",
        "    print(\"\\nSentence:\", sent)\n",
        "\n",
        "    # Step 2: Word tokenization + POS tagging\n",
        "    words = word_tokenize(sent)\n",
        "    tagged = pos_tag(words)\n",
        "\n",
        "    # Step 3: Named Entity Recognition\n",
        "    tree = ne_chunk(tagged)\n",
        "\n",
        "    # Step 4: Extract Named Entities (People, Orgs, Locations, Dates)\n",
        "    entities = []\n",
        "    for subtree in tree:\n",
        "        if hasattr(subtree, 'label'):\n",
        "            entity_name = \" \".join([token for token, pos in subtree.leaves()])\n",
        "            entity_type = subtree.label()\n",
        "            entities.append((entity_name, entity_type))\n",
        "\n",
        "    # Highlight results\n",
        "    if entities:\n",
        "        print(\"➡️ Extracted Entities:\")\n",
        "        for name, etype in entities:\n",
        "            print(f\"   {name}  [{etype}]\")"
      ]
    }
  ]
}